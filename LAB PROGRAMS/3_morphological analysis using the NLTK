import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

nltk.download('punkt')
nltk.download('wordnet')

def simple_morphological_analysis(text):
    # Tokenize the input text into words
    words = word_tokenize(text)
    
    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
    
    return lemmatized_words

# Example usage
text_to_analyze = "The quick brown foxes are jumping over the lazy dogs"

lemmatized_words = simple_morphological_analysis(text_to_analyze)

print("Original text:", text_to_analyze)
print("Lemmatized text:", " ".join(lemmatized_words))
